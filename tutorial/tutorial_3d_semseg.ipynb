{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "#Waymo Open Dataset 3D Semantic Segmentation Tutorial\n",
        "\n",
        "- Website: https://waymo.com/open\n",
        "- GitHub: https://github.com/waymo-research/waymo-open-dataset\n",
        "\n",
        "This tutorial demonstrates how to decode and interpret the 3D semantic segmentation labels. Visit the [Waymo Open Dataset Website](https://waymo.com/open) to download the full dataset.\n",
        "\n",
        "To use, open this notebook in [Colab](https://colab.research.google.com).\n",
        "\n",
        "Uncheck the box \"Reset all runtimes before running\" if you run this colab directly from the remote kernel. Alternatively, you can make a copy before trying to run it by following \"File \u003e Save copy in Drive ...\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sPLur9kMaLh"
      },
      "source": [
        "# Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP9n8ws2N3n5"
      },
      "outputs": [],
      "source": [
        "!pip3 install waymo-open-dataset-tf-2-11-0==1.5.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqs8_62VNc4T"
      },
      "source": [
        "# Imports and global definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuNAlbQpNkLa"
      },
      "outputs": [],
      "source": [
        "# Data location. Please edit.\n",
        "\n",
        "# A tfrecord containing tf.Example protos as downloaded from the Waymo dataset\n",
        "# webpage.\n",
        "\n",
        "# Replace this path with your own tfrecords.\n",
        "FILENAME = '/content/waymo-od/tutorial/.../tfexample.tfrecord'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCDNLdp9Ni8a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from waymo_open_dataset.utils import  frame_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
        "from waymo_open_dataset.protos import segmentation_metrics_pb2\n",
        "from waymo_open_dataset.protos import segmentation_submission_pb2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibor0U9XBlX6"
      },
      "source": [
        "# Read 3D semantic segmentation labels from Frame proto\n",
        " Note that only a subset of the frames have 3d semseg labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O41R3lljM9Ym"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "for data in dataset:\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    if frame.lasers[0].ri_return1.segmentation_label_compressed:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opFz4B9JXC7p"
      },
      "outputs": [],
      "source": [
        "print(frame.context.name)\n",
        "print(frame.context.stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHK95_JBUXUx"
      },
      "outputs": [],
      "source": [
        "(range_images, camera_projections, segmentation_labels,\n",
        " range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(\n",
        "    frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgCDPt9zeV_k"
      },
      "outputs": [],
      "source": [
        "print(segmentation_labels[open_dataset.LaserName.TOP][0].shape.dims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4tCSnwFR3uh"
      },
      "source": [
        "# Visualize Segmentation Labels in Range Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRE_3QhMR7KQ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(64, 20))\n",
        "def plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n",
        "  \"\"\"Plots range image.\n",
        "\n",
        "  Args:\n",
        "    data: range image data\n",
        "    name: the image title\n",
        "    layout: plt layout\n",
        "    vmin: minimum value of the passed data\n",
        "    vmax: maximum value of the passed data\n",
        "    cmap: color map\n",
        "  \"\"\"\n",
        "  plt.subplot(*layout)\n",
        "  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "  plt.title(name)\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "\n",
        "def get_semseg_label_image(laser_name, return_index):\n",
        "  \"\"\"Returns semseg label image given a laser name and its return index.\"\"\"\n",
        "  return segmentation_labels[laser_name][return_index]\n",
        "\n",
        "def show_semseg_label_image(semseg_label_image, layout_index_start = 1):\n",
        "  \"\"\"Shows range image.\n",
        "\n",
        "  Args:\n",
        "    show_semseg_label_image: the semseg label data of type MatrixInt32.\n",
        "    layout_index_start: layout offset\n",
        "  \"\"\"\n",
        "  semseg_label_image_tensor = tf.convert_to_tensor(semseg_label_image.data)\n",
        "  semseg_label_image_tensor = tf.reshape(\n",
        "      semseg_label_image_tensor, semseg_label_image.shape.dims)\n",
        "  instance_id_image = semseg_label_image_tensor[...,0] \n",
        "  semantic_class_image = semseg_label_image_tensor[...,1]\n",
        "  plot_range_image_helper(instance_id_image.numpy(), 'instance id',\n",
        "                   [8, 1, layout_index_start], vmin=-1, vmax=200, cmap='Paired')\n",
        "  plot_range_image_helper(semantic_class_image.numpy(), 'semantic class',\n",
        "                   [8, 1, layout_index_start + 1], vmin=0, vmax=22, cmap='tab20')\n",
        "\n",
        "frame.lasers.sort(key=lambda laser: laser.name)\n",
        "show_semseg_label_image(get_semseg_label_image(open_dataset.LaserName.TOP, 0), 1)\n",
        "show_semseg_label_image(get_semseg_label_image(open_dataset.LaserName.TOP, 1), 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C097jvXXR71D"
      },
      "source": [
        "# Point Cloud Conversion and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QI56Rt1BPuOW"
      },
      "outputs": [],
      "source": [
        "def convert_range_image_to_point_cloud_labels(frame,\n",
        "                                              range_images,\n",
        "                                              segmentation_labels,\n",
        "                                              ri_index=0):\n",
        "  \"\"\"Convert segmentation labels from range images to point clouds.\n",
        "\n",
        "  Args:\n",
        "    frame: open dataset frame\n",
        "    range_images: A dict of {laser_name, [range_image_first_return,\n",
        "       range_image_second_return]}.\n",
        "    segmentation_labels: A dict of {laser_name, [range_image_first_return,\n",
        "       range_image_second_return]}.\n",
        "    ri_index: 0 for the first return, 1 for the second return.\n",
        "\n",
        "  Returns:\n",
        "    point_labels: {[N, 2]} list of 3d lidar points's segmentation labels. 0 for\n",
        "      points that are not labeled.\n",
        "  \"\"\"\n",
        "  calibrations = sorted(frame.context.laser_calibrations, key=lambda c: c.name)\n",
        "  point_labels = []\n",
        "  for c in calibrations:\n",
        "    range_image = range_images[c.name][ri_index]\n",
        "    range_image_tensor = tf.reshape(\n",
        "        tf.convert_to_tensor(range_image.data), range_image.shape.dims)\n",
        "    range_image_mask = range_image_tensor[..., 0] \u003e 0\n",
        "\n",
        "    if c.name in segmentation_labels:\n",
        "      sl = segmentation_labels[c.name][ri_index]\n",
        "      sl_tensor = tf.reshape(tf.convert_to_tensor(sl.data), sl.shape.dims)\n",
        "      sl_points_tensor = tf.gather_nd(sl_tensor, tf.where(range_image_mask))\n",
        "    else:\n",
        "      num_valid_point = tf.math.reduce_sum(tf.cast(range_image_mask, tf.int32))\n",
        "      sl_points_tensor = tf.zeros([num_valid_point, 2], dtype=tf.int32)\n",
        "      \n",
        "    point_labels.append(sl_points_tensor.numpy())\n",
        "  return point_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSAbxSW0RAQo"
      },
      "outputs": [],
      "source": [
        "points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame, range_images, camera_projections, range_image_top_pose)\n",
        "points_ri2, cp_points_ri2 = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame, range_images, camera_projections, range_image_top_pose, ri_index=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgUcnL9IRMZs"
      },
      "outputs": [],
      "source": [
        "point_labels = convert_range_image_to_point_cloud_labels(\n",
        "    frame, range_images, segmentation_labels)\n",
        "point_labels_ri2 = convert_range_image_to_point_cloud_labels(\n",
        "    frame, range_images, segmentation_labels, ri_index=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdYRcWdRRWmc"
      },
      "outputs": [],
      "source": [
        "# 3d points in vehicle frame.\n",
        "points_all = np.concatenate(points, axis=0)\n",
        "points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
        "# point labels.\n",
        "point_labels_all = np.concatenate(point_labels, axis=0)\n",
        "point_labels_all_ri2 = np.concatenate(point_labels_ri2, axis=0)\n",
        "# camera projection corresponding to each point.\n",
        "cp_points_all = np.concatenate(cp_points, axis=0)\n",
        "cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCj3SDbuq9Nr"
      },
      "source": [
        "###Show colored point cloud\n",
        "Example of rendered point clouds (this tutorial does not have visualization capability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8VFnGnOq6cO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "!wget https://raw.githubusercontent.com/waymo-research/waymo-open-dataset/master/tutorial/3d_semseg_points.png\n",
        "display(Image('/content/3d_semseg_points.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37g8RIQhNMm7"
      },
      "source": [
        "# Create a dummy submission file for the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaC7-BrlNQIz"
      },
      "outputs": [],
      "source": [
        "import zlib\n",
        "\n",
        "def compress_array(array: np.ndarray, is_int32: bool = False):\n",
        "  \"\"\"Compress a numpy array to ZLIP compressed serialized MatrixFloat/Int32.\n",
        "\n",
        "  Args:\n",
        "    array: A numpy array.\n",
        "    is_int32: If true, use MatrixInt32, otherwise use MatrixFloat.\n",
        "\n",
        "  Returns:\n",
        "    The compressed bytes.\n",
        "  \"\"\"\n",
        "  if is_int32:\n",
        "    m = open_dataset.MatrixInt32()\n",
        "  else:\n",
        "    m = open_dataset.MatrixFloat()\n",
        "  m.shape.dims.extend(list(array.shape))\n",
        "  m.data.extend(array.reshape([-1]).tolist())\n",
        "  return zlib.compress(m.SerializeToString())\n",
        "\n",
        "def decompress_array(array_compressed: bytes, is_int32: bool = False):\n",
        "  \"\"\"Decompress bytes (of serialized MatrixFloat/Int32) to a numpy array.\n",
        "\n",
        "  Args:\n",
        "    array_compressed: bytes.\n",
        "    is_int32: If true, use MatrixInt32, otherwise use MatrixFloat.\n",
        "\n",
        "  Returns:\n",
        "    The decompressed numpy array.\n",
        "  \"\"\"\n",
        "  decompressed = zlib.decompress(array_compressed)\n",
        "  if is_int32:\n",
        "    m = open_dataset.MatrixInt32()\n",
        "    dtype = np.int32\n",
        "  else:\n",
        "    m = open_dataset.MatrixFloat()\n",
        "    dtype = np.float32\n",
        "  m.ParseFromString(decompressed)\n",
        "  return np.array(m.data, dtype=dtype).reshape(m.shape.dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZTjFN_CNlNx"
      },
      "outputs": [],
      "source": [
        "TOP_LIDAR_ROW_NUM = 64\n",
        "TOP_LIDAR_COL_NUM = 2650"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P9hToEvNUUJ"
      },
      "outputs": [],
      "source": [
        "def get_range_image_point_indexing(range_images, ri_index=0):\n",
        "  \"\"\"Get the indices of the valid points (of the TOP lidar) in the range image.\n",
        "\n",
        "  The order of the points match those from convert_range_image_to_point_cloud\n",
        "  and convert_range_image_to_point_cloud_labels.\n",
        "\n",
        "  Args:\n",
        "    range_images: A dict of {laser_name, [range_image_first_return,\n",
        "       range_image_second_return]}.\n",
        "    ri_index: 0 for the first return, 1 for the second return.\n",
        "\n",
        "  Returns:\n",
        "    points_indexing_top: (N, 2) col and row indices of the points in the\n",
        "      TOP lidar.\n",
        "  \"\"\"\n",
        "  points_indexing_top = None\n",
        "  xgrid, ygrid = np.meshgrid(range(TOP_LIDAR_COL_NUM), range(TOP_LIDAR_ROW_NUM))\n",
        "  col_row_inds_top = np.stack([xgrid, ygrid], axis=-1)\n",
        "  range_image = range_images[open_dataset.LaserName.TOP][ri_index]\n",
        "  range_image_tensor = tf.reshape(\n",
        "      tf.convert_to_tensor(range_image.data), range_image.shape.dims)\n",
        "  range_image_mask = range_image_tensor[..., 0] \u003e 0\n",
        "  points_indexing_top = col_row_inds_top[np.where(range_image_mask)]\n",
        "  return points_indexing_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0ijObegNgHc"
      },
      "outputs": [],
      "source": [
        "def dummy_semseg_for_one_frame(frame, dummy_class=14):\n",
        "  \"\"\"Assign all valid points to a single dummy class.\n",
        "\n",
        "  Args:\n",
        "    frame: An Open Dataset Frame proto.\n",
        "    dummy_class: The class to assign to. Default is 14 (building).\n",
        "\n",
        "  Returns:\n",
        "    segmentation_frame: A SegmentationFrame proto.\n",
        "  \"\"\"\n",
        "  (range_images, camera_projections, segmentation_labels,\n",
        "   range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(\n",
        "       frame)\n",
        "  # Get the col, row indices of the valid points.\n",
        "  points_indexing_top = get_range_image_point_indexing(range_images, ri_index=0)\n",
        "  points_indexing_top_ri2 = get_range_image_point_indexing(\n",
        "      range_images, ri_index=1)\n",
        "  # Assign the dummy class to all valid points (in the range image)\n",
        "  range_image_pred = np.zeros(\n",
        "      (TOP_LIDAR_ROW_NUM, TOP_LIDAR_COL_NUM, 2), dtype=np.int32)\n",
        "  range_image_pred[points_indexing_top[:, 1],\n",
        "                   points_indexing_top[:, 0], 1] = dummy_class\n",
        "  range_image_pred_ri2 = np.zeros(\n",
        "      (TOP_LIDAR_ROW_NUM, TOP_LIDAR_COL_NUM, 2), dtype=np.int32)\n",
        "  range_image_pred_ri2[points_indexing_top_ri2[:, 1],\n",
        "                       points_indexing_top_ri2[:, 0], 1] = dummy_class\n",
        "  # Construct the SegmentationFrame proto.\n",
        "  segmentation_frame = segmentation_metrics_pb2.SegmentationFrame()\n",
        "  segmentation_frame.context_name = frame.context.name\n",
        "  segmentation_frame.frame_timestamp_micros = frame.timestamp_micros\n",
        "  laser_semseg = open_dataset.Laser()\n",
        "  laser_semseg.name = open_dataset.LaserName.TOP\n",
        "  laser_semseg.ri_return1.segmentation_label_compressed = compress_array(\n",
        "      range_image_pred, is_int32=True)\n",
        "  laser_semseg.ri_return2.segmentation_label_compressed = compress_array(\n",
        "      range_image_pred_ri2, is_int32=True)\n",
        "  segmentation_frame.segmentation_labels.append(laser_semseg)\n",
        "  return segmentation_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3iz5MazOhPy"
      },
      "outputs": [],
      "source": [
        "# Create the dummy pred file for the validation set run segments.\n",
        "\n",
        "# Replace this path with the real path to the WOD validation set folder.\n",
        "folder_name = '/content/waymo-od/.../validation/'\n",
        "\n",
        "filenames = [os.path.join(folder_name, x) for x in os.listdir(\n",
        "    folder_name) if 'tfrecord' in x]\n",
        "assert(len(filenames) == 202)\n",
        "\n",
        "segmentation_frame_list = segmentation_metrics_pb2.SegmentationFrameList()\n",
        "for idx, filename in enumerate(filenames):\n",
        "  if idx % 10 == 0:\n",
        "    print('Processing %d/%d run segments...' % (idx, len(filenames)))\n",
        "  dataset = tf.data.TFRecordDataset(filename, compression_type='')\n",
        "  for data in dataset:\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    if frame.lasers[0].ri_return1.segmentation_label_compressed:\n",
        "      segmentation_frame = dummy_semseg_for_one_frame(frame)\n",
        "      segmentation_frame_list.frames.append(segmentation_frame)\n",
        "print('Total number of frames: ', len(segmentation_frame_list.frames))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_YlqK4RR8pR"
      },
      "outputs": [],
      "source": [
        "# Create the submission file, which can be uploaded to the eval server.\n",
        "submission = segmentation_submission_pb2.SemanticSegmentationSubmission()\n",
        "submission.account_name = 'joe@gmail.com'\n",
        "submission.unique_method_name = 'JoeNet'\n",
        "submission.affiliation = 'Smith Inc.'\n",
        "submission.authors.append('Joe Smith')\n",
        "submission.description = \"A dummy method by Joe (val set).\"\n",
        "submission.method_link = 'NA'\n",
        "submission.sensor_type = 1\n",
        "submission.number_past_frames_exclude_current = 2\n",
        "submission.number_future_frames_exclude_current = 0\n",
        "submission.inference_results.CopyFrom(segmentation_frame_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrCD59OkR_wK"
      },
      "outputs": [],
      "source": [
        "output_filename = '/tmp/wod_semseg_val_set_dummy_pred_submission.bin'\n",
        "f = open(output_filename, 'wb')\n",
        "f.write(submission.SerializeToString())\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIjNwn3bSTec"
      },
      "source": [
        "# Create a dummy submission file for the testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-fJxQHXSVVk"
      },
      "outputs": [],
      "source": [
        "# Create the dummy pred file for the testing set run segments.\n",
        "\n",
        "# Replace the paths with the real paths to the WOD testing set folders.\n",
        "folder_name1 = '/content/waymo-od/.../testing/'\n",
        "folder_name2 = '/content/waymo-od/.../testing_location/'\n",
        "filenames1 = [os.path.join(folder_name1, x) for x in os.listdir(\n",
        "    folder_name1) if 'tfrecord' in x]\n",
        "filenames2 = [os.path.join(folder_name2, x) for x in os.listdir(\n",
        "    folder_name2) if 'tfrecord' in x]\n",
        "filenames = filenames1 + filenames2\n",
        "print(len(filenames))\n",
        "assert(len(filenames) == 150)\n",
        "\n",
        "# Replace this path with the real path. The file is under:\n",
        "# /waymo-open-dataset/tutorial/ in the github repo.\n",
        "# Each line of the file is the \"\u003ccontext_name\u003e, \u003ctimestamp_micros\u003e\" of a frame\n",
        "# with semseg labels. \n",
        "testing_set_frame_file = '/path/3d_semseg_test_set_frames.txt'\n",
        "context_name_timestamp_tuples = [x.rstrip().split(',') for x in (\n",
        "    open(testing_set_frame_file, 'r').readlines())]\n",
        "\n",
        "segmentation_frame_list = segmentation_metrics_pb2.SegmentationFrameList()\n",
        "for idx, filename in enumerate(filenames):\n",
        "  if idx % 10 == 0:\n",
        "    print('Processing %d/%d run segments...' % (idx, len(filenames)))\n",
        "  dataset = tf.data.TFRecordDataset(filename, compression_type='')\n",
        "  for data in dataset:\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    context_name = frame.context.name\n",
        "    timestamp = frame.timestamp_micros\n",
        "    if (context_name, str(timestamp)) in context_name_timestamp_tuples:\n",
        "      print(context_name, timestamp)\n",
        "      segmentation_frame = dummy_semseg_for_one_frame(frame)\n",
        "      segmentation_frame_list.frames.append(segmentation_frame)\n",
        "print('Total number of frames: ', len(segmentation_frame_list.frames))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30q-hzjQljYc"
      },
      "outputs": [],
      "source": [
        "# Create the submission file, which can be uploaded to the eval server.\n",
        "submission = segmentation_submission_pb2.SemanticSegmentationSubmission()\n",
        "submission.account_name = 'joe@gmail.com'\n",
        "submission.unique_method_name = 'JoeNet'\n",
        "submission.affiliation = 'Smith Inc.'\n",
        "submission.authors.append('Joe Smith')\n",
        "submission.description = \"A dummy method by Joe (test set).\"\n",
        "submission.method_link = 'NA'\n",
        "submission.sensor_type = 1\n",
        "submission.number_past_frames_exclude_current = 2\n",
        "submission.number_future_frames_exclude_current = 0\n",
        "submission.inference_results.CopyFrom(segmentation_frame_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oStSwaE-Sv5Y"
      },
      "outputs": [],
      "source": [
        "output_filename = '/tmp/wod_semseg_test_set_dummy_pred_submission.bin'\n",
        "f = open(output_filename, 'wb')\n",
        "f.write(submission.SerializeToString())\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Waymo Open Dataset 3D Semantic Segmentation Tutorial.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "tutorial_3d_semseg.ipynb",
          "timestamp": 1649874845881
        },
        {
          "file_id": "tutorial.ipynb",
          "timestamp": 1644287712198
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
